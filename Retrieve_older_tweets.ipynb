{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You're at right place. Take a deep breath and code with me ;p "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements:\n",
    "* The most obvious one is Twitter Developer Account.\n",
    "* Jupyter Notebook (You can use any other IDE also as per your choice.)\n",
    "* tweepy (Tweepy is a python library to access Twitter API.)\n",
    "* snscrape (snscrape is a scraper for social networking services (SNS))\n",
    "* pandas(Pandas is an open-source, BSD-licensed Python library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's import the libraries that are required here.\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide your own credentials here.\n",
    "consumer_key = '#######################################'\n",
    "consumer_secret = '####################################'\n",
    "access_token = '#######################################'\n",
    "access_token_secret = '################################'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snscrape → snscrape is a scraper for social networking services (SNS). We need to install this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/PortalAmazonas1/status/134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/EsNoticiaMundia/status/134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/kesedice/status/1345520103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/robertoleoni/status/134552...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/WFTSisabel/status/13455200...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_urls\n",
       "0  https://twitter.com/PortalAmazonas1/status/134...\n",
       "1  https://twitter.com/EsNoticiaMundia/status/134...\n",
       "2  https://twitter.com/kesedice/status/1345520103...\n",
       "3  https://twitter.com/robertoleoni/status/134552...\n",
       "4  https://twitter.com/WFTSisabel/status/13455200..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To open and read the file .txt or .json using read_csv() and read_json() of pandas respectively.\n",
    "tweet_url = pd.read_csv(\"scraped_tweets.txt\", index_col= None, header = None, names = [\"tweet_urls\"])\n",
    "tweet_url.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the tweet id\n",
    "af = lambda x: x[\"tweet_urls\"].split(\"/\")[-1]\n",
    "#store tweet id in another column\n",
    "tweet_url['tweet_id'] = tweet_url.apply(af, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_urls</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/PortalAmazonas1/status/134...</td>\n",
       "      <td>1345520153992323072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/EsNoticiaMundia/status/134...</td>\n",
       "      <td>1345520135508025345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/kesedice/status/1345520103...</td>\n",
       "      <td>1345520103044096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/robertoleoni/status/134552...</td>\n",
       "      <td>1345520083234414592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/WFTSisabel/status/13455200...</td>\n",
       "      <td>1345520013244047365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_urls             tweet_id\n",
       "0  https://twitter.com/PortalAmazonas1/status/134...  1345520153992323072\n",
       "1  https://twitter.com/EsNoticiaMundia/status/134...  1345520135508025345\n",
       "2  https://twitter.com/kesedice/status/1345520103...  1345520103044096000\n",
       "3  https://twitter.com/robertoleoni/status/134552...  1345520083234414592\n",
       "4  https://twitter.com/WFTSisabel/status/13455200...  1345520013244047365"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_url.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, let’s convert our tweet_url Series into a list.\n",
    "ids = tweet_url['tweet_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#When I looped through all the 3400 ids, the API is giving an error. Therefore, I tried to process the ids by batch or chunks.\n",
    "total_count = len(ids)\n",
    "chunks = (total_count - 1) // 50 + 1\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can finally create our function that would extract all the elements that we need from the tweet. \n",
    "#Here, only the tweet id, tweet time and the tweet itself is required.\n",
    "def fetch_tw(ids):\n",
    "    tw_statuses = api.statuses_lookup(ids, tweet_mode= \"extended\")\n",
    "    data = pd.DataFrame()\n",
    "    for status in tw_statuses:\n",
    "            tweet_elem = {\"tweet_id\": status.id,\n",
    "                     \"tweet\":status.full_text,\n",
    "                     \"date\":status.created_at}\n",
    "            data = data.append(tweet_elem, ignore_index = True)\n",
    "    data.to_csv(\"scraped_tweets.csv\", mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll process only 50 entries because the statuses_lookup() method gives the statuses of IDs, up to 100 only..\n",
    "for i in range(chunks):\n",
    "        lst = ids[i*50:(i+1)*50]\n",
    "        result = fetch_tw(lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A csv file is already created with the older tweets information. Please check and carry out your further tasks :)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
